%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% template: https://www.overleaf.com/latex/templates/imperial-assignment-template/pbnrncvckyjv

%Packages
\documentclass[10pt, a4paper]{article}
\usepackage[top=3cm, bottom=4cm, left=3.5cm, right=3.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd, fancyhdr, color, comment, graphicx, environ}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage{unicode-math}
% \setmathfont{TeX Gyre Termes Math}
\usepackage{lastpage}
\usepackage[dvipsnames]{xcolor}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage{fancyhdr}
\usepackage{indentfirst}
\usepackage{listings}
\usepackage{sectsty}
\usepackage{thmtools}
\usepackage{shadethm}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage[linguistics]{forest}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Environment setup
\mdfsetup{skipabove=\topskip,skipbelow=\topskip}
\newrobustcmd\ExampleText{%
An \textit{inhomogeneous linear} differential equation has the form
\begin{align}
L[v ] = f,
\end{align}
where $L$ is a linear differential operator, $v$ is the dependent
variable, and $f$ is a given non−zero function of the independent
variables alone.
}
\mdfdefinestyle{theoremstyle}{%
linecolor=black,linewidth=1pt,%
frametitlerule=true,%
frametitlebackgroundcolor=gray!20,
innertopmargin=\topskip,
}
\mdtheorem[style=theoremstyle]{Problem}{Problem}
\newenvironment{Solution}{\textbf{Solution.}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Fill in the appropriate information below
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand\course{Machine Learning - Supervised Learning}
\newcommand\hwnumber{M-MLR-900}
\newcommand\Information{(Alexandre Guichet, Alexis Auriac, Benjamin Feller)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Page setup
\pagestyle{fancy}
\headheight 35pt
\lhead{\today}
\rhead{\includegraphics[width=2.5cm]{epitech_logo.png}}
\lfoot{}
\pagenumbering{arabic}
\cfoot{\small\thepage}
\rfoot{}
\headsep 1.2em
\renewcommand{\baselinestretch}{1.25}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Add new commands here
\renewcommand{\labelenumi}{\alph{enumi})}
\newcommand{\Z}{\mathbb Z}
\newcommand{\R}{\mathbb R}
\newcommand{\Q}{\mathbb Q}
\newcommand{\NN}{\mathbb N}
\newcommand{\PP}{\mathbb P}
\DeclareMathOperator{\Mod}{Mod} 
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}
\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
\newtheorem{case}{Case}
\newcommand{\assign}{:=}
\newcommand{\infixiff}{\text{ iff }}
\newcommand{\nobracket}{}
\newcommand{\backassign}{=:}
\newcommand{\tmmathbf}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmtextbf}[1]{\text{{\bfseries{#1}}}}
\newcommand{\tmtextit}[1]{\text{{\itshape{#1}}}}

\newenvironment{itemizedot}{\begin{itemize} \renewcommand{\labelitemi}{$\bullet$}\renewcommand{\labelitemii}{$\bullet$}\renewcommand{\labelitemiii}{$\bullet$}\renewcommand{\labelitemiv}{$\bullet$}}{\end{itemize}}
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}
\catcode`\>=\active \def>{
\fontencoding{T1}\selectfont\symbol{62}\fontencoding{\encodingdefault}}
\catcode`\<=\active \def<{
\fontencoding{T1}\selectfont\symbol{60}\fontencoding{\encodingdefault}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Begin now!

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{3cm}
            
        \Huge
        \textbf{Report}
            
        \vspace{1cm}
        \huge
        \hwnumber
            
        \vspace{1.5cm}
        \Large
            
        \textbf{\Information}                      % <-- author
        
            
        \vfill
        
        \course
            
        \vspace{1cm}
            
        \includegraphics[width=0.4\textwidth]{epitech_logo.png}

        \Large
        
        \today
            
    \end{center}
\end{titlepage}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Introduction}

We did part 1, 2, 3, and 4, we did not have time to finish part 5.

\subsection*{Division of labor}

\begin{itemize}
    \item Alexandre: part 1
    \item Benjamin: part 2
    \item Alexis: part 3, 4, and 5, writing report
\end{itemize}

\subsection*{Additional dependencies}

We used the following additional dependencies:

\begin{itemize}
    \item geopy: to compute distances between coordinates, see part 2
    \item statsmodels: for data exploration, see part 4
\end{itemize}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Part 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Part 1}

\begin{Problem}
    The goal of this exercise is to work with statistical notions such as mean, standard deviation, and correlation.

    Write a file named artificial\_dataset.py that generates a numerical dataset with 300 datapoints (i.e. lines) and at least 6 columns and saves it to a csv file or to a numpy array in a binary python file.

    The columns must satisfy the following requirements:
    \begin{itemize}
        \item they must all have a different mean
        \item they must all have a different standard deviation (English for "écart type")
        \item at least one column should contain integers.
        \item at least one column should contain floats.
        \item one column must have a mean close to 2.5.
        \item some columns must be positively correlated.
        \item some columns must be negatively correlated.
        \item some columns must have a correlation close to 0.
    \end{itemize}
\end{Problem}

\newpage

\begin{Solution}

See \verb|exercise_1/artificial_dataset.py| for the code.

The generated data can be found in \verb|exercise_1/data.npy|, it contains 300 dataponts with 6 columns.

Let's go over each point mentioned in the subject one by one.

\subsubsection*{All columns must have a different mean}

\begin{itemize}
    \item column 1: 2.58
    \item column 2: 0.898
    \item column 3: 1.686
    \item column 4: 4.707
    \item column 5: 0.349
    \item column 6: 10.115
\end{itemize}

\subsubsection*{All columns must have a different standard deviation}

\begin{itemize}
    \item column 1: 1.752
    \item column 2: 0.827
    \item column 3: 1.998
    \item column 4: 1.889
    \item column 5: 2.430
    \item column 6: 1.352
\end{itemize}

\subsubsection*{At least one column should contain integers}

Column 1 contains integers.

\subsubsection*{At least one column should contain floats}

All columns except column 1 contain floats.

\subsubsection*{One column must have a mean close to 2.5}

Column 1 has a mean of 2.58.

\subsubsection*{Columns correlations}

Using \verb|numpy.corrcoef| to get a correlation matrix for column 4, 5, and 6 we get this:

\hfill

\begin{center}
    $
    \begin{pmatrix}
        1. & -0.5595593 & 0.66913029\\
        -0.5595593 & 1. & 0.03168539\\
        0.66913029 & 0.03168539 & 1.
    \end{pmatrix}
    $
\end{center}

\hfill

Column 4 is \textbf{negatively correlated} with column 5.

Column 4 is \textbf{positively correlated} with column 6.

Column 5 is \textbf{has a correlation close to 0} with column 6.

\end{Solution}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Part 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Part 2}

\begin{Problem}
    A dataset representing a population is stored in dataset.csv inside the

    \verb|project/ex_2_metric/folder|.

    Define a metric in this dataset, which means define a dissimilarity between the samples, by taking into account all their features (columns of the dataset).

    Some features are numerical and others are categorical, hence you can not use a standard euclidean metric, and you need to define a custom metric, like we did in the \verb|code/metrics/hybrid_data/| exercise during the course. Compute the mean dissimilarity and the standard deviation of the dissimilarity distribution that you obtain, and save the dissimilarity matrix to a file (e.g. a npy file).

    Importantly, you must define and explain which features are more important with this metric, since you have to balance the contribution of all the features. Your metric should be meaningful in the sense that not all feature values should induce the same contribution to the dissimilarity : the music style "technical death metal" is closer to "metal" than it is to "classical".
\end{Problem}

\begin{Solution}

The columns in the dataset are age, height, job, city, and favorite music style.

The age and height features are numerical and their dissimilarity can be computed using the euclidean distance.

The job, city, and favorite music style features are not numerical so we must define a custom metric for each of them.

\newpage

\subsubsection*{Job}

See \verb|job.py| for the code.

Here are the jobs we can find in the dataset: designer, fireman, teacher, doctor, painter, developper, and engineer.

We will assign an art, science, and altruism value from 0 to 10 for each job.

The values given are VERY subjective, we don't mean any offense.

\hfill

\begin{center}
    \begin{tabular}{||c c c c||}
        \hline
        & art & science & altruism \\
        \hline\hline
        designer & 8 & 3 & 4 \\
        \hline
        fireman & 0 & 7 & 10 \\
        \hline
        teacher & 4 & 5 & 6 \\
        \hline
        doctor & 2 & 9 & 8 \\
        \hline
        painter & 10 & 2 & 3 \\
        \hline
        developper & 3 & 6 & 1 \\
        \hline
        engineer & 4 & 8 & 2 \\
        \hline
    \end{tabular}
\end{center}

Using the euclidean distance we get the following dissimilarity matrix:

\begin{center}
    \begin{tabular}{||c c c c c c c c||}
        \hline
        & designer & fireman & teacher & doctor & painter & developper & engineer \\
        \hline\hline
        designer & 0.000000 & 10.770330 & 4.898979 & 9.380832 & 2.449490 & 6.557439 & 6.708204 \\
        \hline
        fireman & 10.770330 & 0.000000 & 6.000000 & 3.464102 & 13.190906 & 9.539392 & 9.000000 \\
        \hline
        teacher & 4.898979 & 6.000000 & 0.000000 & 4.898979 & 7.348469 & 5.196152 & 5.000000 \\
        \hline
        doctor & 9.380832 & 3.464102 & 4.898979 & 0.000000 & 11.747340 & 7.681146 & 6.403124 \\
        \hline
        painter & 2.449490 & 13.190906 & 7.348469 & 11.747340 & 0.000000 & 8.306624 & 8.544004 \\
        \hline
        developper & 6.557439 & 9.539392 & 5.196152 & 7.681146 & 8.306624 & 0.000000 & 2.449490 \\
        \hline
        engineer & 6.708204 & 9.000000 & 5.000000 & 6.403124 & 8.544004 & 2.449490 & 0.000000 \\
        \hline
    \end{tabular}
\end{center}

We can see that jobs like painter and fireman have a high dissimilarity (13.2) while painter and designer have a low dissimilarity (2.4).

\newpage

\subsubsection*{City}

See \verb|city.py| for the code.

Here are the cities we can find in the dataset: paris, marseille, toulouse, madrid, and lille.

We will evaluate cities using 4 metrics: distance (using coordinates), population, country, and if it is a capital.

Here is the data we used:

\begin{center}
    \begin{tabular}{||c c c c c||}
        \hline
        & coordinates & population & country & capital \\
        \hline\hline
        paris & (48.8566, 2.3522) & 2161000 & France & True \\
        \hline
        marseille & (43.2965, 5.3698) & 861635 & France & False \\
        \hline
        toulouse & (43.6047, 1.4442) & 471941 & France & False \\
        \hline
        madrid & (40.4168, 3.7038) & 3223000 & Spain & True \\
        \hline
        lille & (50.6292, 3.0573) & 232741 & France & False \\
        \hline
    \end{tabular}
\end{center}

To measure distance we use the library geopy we then use log10 so that it doesn't impact the dissimilarity too much.

We compare the population using euclidean distance. We then use log10 so that it doesn't impact the dissimilarity too much.

Not being from the same country adds a dissimilarity of 10.

One being a capital and not the other adds a dissimilarity of 5.

We then compute the square root of the sum of the squares to get the dissimilarity.

Using this method we get the following dissimilarity matrix:

\begin{center}
    \begin{tabular}{||c c c c c c||}
        \hline
        & paris & marseille & toulouse & madrid & lille \\
        \hline\hline
        paris & 0.000000 & 7.897956 & 7.986461 & 11.675366 & 8.031395 \\
        \hline
        marseille & 7.897956 & 0.000000 & 5.590724 & 12.869235 & 5.798577 \\
        \hline
        toulouse & 7.986461 & 5.590724 & 0.000000 & 12.902215 & 5.378761 \\
        \hline
        madrid & 11.675366 & 12.869235 & 12.902215 & 0.000000 & 12.920325 \\
        \hline
        lille & 8.031395 & 5.798577 & 5.378761 & 12.920325 & 0.000000 \\
        \hline
    \end{tabular}
\end{center}

\newpage

\subsubsection*{Favorite music style}

See \verb|music.py| for the code.

Here are the cities we can find in the dataset: trap, hiphop, metal, rock, rap, classical, other, jazz, and technical death metal.

It is hard to find metrics for music styles, we decided to give each pair of music styles a dissimilarity based on personal knowledge.

Some important assumptions that influenced our choices:

\begin{itemize}
    \item trap, hiphop, and rap are related
    \item metal, rock, and technical death metal are related
    \item other is very vague and large, so we gave it a dissimilarity of 10 for all music styles
\end{itemize}

We get this dissimilarity matrix:

\begin{center}
    \begin{tabular}{||c c c c c c c c c c||}
        \hline
        & trap & hiphop & metal & rock & rap & classical & other & jazz & technical death metal \\
        \hline\hline
        trap & 0 & 3 & 20 & 20 & 5 & 20 & 10 & 15 & 20 \\
        \hline
        hiphop & 3 & 0 & 18 & 17 & 5 & 15 & 10 & 12 & 20 \\
        \hline
        metal & 20 & 18 & 0 & 5 & 10 & 14 & 10 & 20 & 5 \\
        \hline
        rock & 20 & 17 & 5 & 0 & 10 & 12 & 10 & 17 & 13 \\
        \hline
        rap & 5 & 5 & 10 & 10 & 0 & 15 & 10 & 15 & 20 \\
        \hline
        classical & 20 & 15 & 14 & 12 & 15 & 0 & 10 & 8 & 20 \\
        \hline
        other & 10 & 10 & 10 & 10 & 10 & 10 & 0 & 10 & 10 \\
        \hline
        jazz & 15 & 12 & 20 & 17 & 15 & 8 & 10 & 0 & 20 \\
        \hline
        technical death metal & 20 & 20 & 5 & 13 & 20 & 20 & 10 & 20 & 0 \\
        \hline
    \end{tabular}
\end{center}

\newpage

\subsection*{Overall dissimilarity}

\subsubsection*{Adjusting means}

See \verb|exercise_2.py| for the code.

If we look at the means and standard deviation for each column we get

\begin{center}
    \begin{tabular}{||c c c||}
        \hline
        & mean & std \\
        \hline\hline
        age & 6.456159 & 4.892174 \\
        \hline
        height & 6.000623 & 4.679549 \\
        \hline
        job & 6.259779 & 3.747122 \\
        \hline
        city & 6.950629 & 5.205568 \\
        \hline
        favorite music style & 11.796500 & 6.390359 \\
        \hline
    \end{tabular}
\end{center}

The mean isn't the same, which means that because of the way we compute dissimilarity some columns have inherently more value, that's an issue. It also makes standard deviations impossible to compare.

We will try to have all means equal 10 (10 is arbitrary, it makes things relatively readable).

After adjustment we get the following:

\begin{center}
    \begin{tabular}{||c c c c||}
        \hline
        & mean & std & adjusted std \\
        \hline\hline
        age & 6.456159 & 4.892174 & 7.577531 \\
        \hline
        height & 6.000623 & 4.679549 & 7.798439 \\
        \hline
        job & 6.259779 & 3.747122 & 5.986029 \\
        \hline
        city & 6.950629 & 5.205568 & 7.489348 \\
        \hline
        favorite music style & 11.796500 & 6.390359 & 5.417165 \\
        \hline
    \end{tabular}
\end{center}

\subsection*{Deciding feature importance}

\textbf{Age}: The age of a person changes a lot of a person, beliefs, physical ability, experience, etc...

$\Rightarrow 3$

\textbf{Height}: Beside appearance and physical ability (in some contexts) this doesn't change much

$\Rightarrow 1$

\textbf{Job}: job is closely related to knowledge, ability, wealth, status, and more

$\Rightarrow 3$

\textbf{City}: Geographical location is related to culture, opportunities, language, and more

$\Rightarrow 2.5$

\textbf{Favorite music style}: As explained before, this dissimilarity is very hard to measure and music styles have a lot of intersections

$\Rightarrow 0.5$

\subsection*{Result matrix}

See \verb|dissimilarity_matrix.npy| for the final dissimilarity matrix.

mean: 58.386

standard deviation: 19.976

\subsubsection*{Side note: most similar and dissimilar items}

Most similar items:
\begin{center}
    \begin{tabular}{||c c c c c c||}
        \hline
        & age & height & job & city & favorite music style \\
        \hline\hline
        102 & 27.086348 & 180.242244 & teacher & madrid & jazz \\
        \hline
        163 & 26.968458 & 179.665081 & teacher & madrid & jazz \\
        \hline
    \end{tabular}
\end{center}

Most dissimilar items:
\begin{center}
    \begin{tabular}{||c c c c c c||}
        \hline
        & age & height & job & city & favorite music style \\
        \hline\hline
        40 & 10.851506 & 169.432515 & fireman & lille & jazz \\
        \hline
        85 & 46.610179 & 181.358551 & fireman & toulouse & trap \\
        \hline
    \end{tabular}
\end{center}

\end{Solution}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Part 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Part 3}

\begin{Problem}
    We would like to predict the winner of a Basketball game, as a function of the data gathered at half-time.

    The dataset is stored in \verb|project/ex_3_classification_NBA/|:
    \begin{itemize}
        \item The inputs x representing the features are stored in \verb|inputs.npy|.
        \item The labels y are stored in \verb|labels.npy|. If the home team wins, the label is 1, -1 otherwise.
    \end{itemize}

    You are free to choose the classification method. However, it is required that you explain and discuss your approach in your report. For instance, you could discuss:
    \begin{itemize}
        \item the performance of several methods and models that you tried.
        \item the choice of the hyperparameters and the method to tune them.
        \item the optimization procedure.
    \end{itemize}

    Your objective should be to obtain a mean accuracy superior than 0.85 on a test set or as a cross validation score.

    \href{https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score}{scikit-learn model validation and accuracy score}

    \href{https://scikit-learn.org/stable/modules/cross_validation.html}{scikit-learn cross validation}

    Several methods might work, including some methods that we have not explicitely studied in the class. Do not hesitate to try such methods.
\end{Problem}

\begin{Solution}

I tried 3 models for this exercise: KNeighbors, RandomForest and Logistic Regression.

For each model I chose some hyperparameters to tune and then used GridSearchCV or RandomizedSearchCV to tune them and measure the mean accuracy of the model.

GridSearchCV and RandomizedSearchCV both use cross validation.

\newpage

\subsection*{KNeighbors Classifier}

See \verb|kneighbors.py| for the code.

Hyperparameters:
\begin{itemize}
    \item n\_neighbors: can cause overfitting or underfitting if it is too small or too big respectively
    \item weights: give all points the same or a different importance
    \item p: distance measure, 1 is for manhattan, 2 is for euclidean
\end{itemize}

The best hyperparameters found using GridSearchCV were:
\begin{lstlisting}[language=Python]
{
    'n_neighbors': 11,
    'p': 2,
    'weights': 'uniform'
}
\end{lstlisting}

They give a mean score of 0.804.

\subsection*{RandomForest Classifier}

See \verb|random_forest.py| for the code.

Hyperparameters:
\begin{itemize}
    \item n\_estimators: number of trees
    \item max\_features: number of features to consider at every split
    \item max\_depth: maximum number of levels in tree
    \item min\_samples\_split: minimum number of samples required to split a node
    \item min\_samples\_leaf: minimum number of samples required at each leaf node
    \item bootstrap: method of selecting samples for training each tree
\end{itemize}

The best hyperparameters found using ```RandomizedSearchCV``` were:
\begin{lstlisting}[language=Python]
{
    'n_estimators': 400,
    'min_samples_split': 10,
    'min_samples_leaf': 4,
    'max_features': 'sqrt',
    'max_depth': None,
    'bootstrap': False
}
\end{lstlisting}

They give a mean score of 0.816.

\subsection*{LogisticRegression}

See \verb|logistic_regression.py| for the code.

Hyperparameters:
\begin{itemize}
    \item C: controls regularization strength (prevents overfitting)
    \item solver: some solvers are better depending on: number of features, size of dataset, number of classes, etc...
    \item max\_iter: maximum number of iterations taken for the solvers to converge
\end{itemize}

I am confused about the penalty hyperparameter, it seems to be deprecated in favor of solver but I am not sure. Furthermore only some values of solver are compatible with some values of penalty, I am not sure how to take that into account when using GridSearchCV or RandomizedSearchCV. I eventually decided to exclude it from the tuning.

The best parameters found using GridSearchCV were:
\begin{lstlisting}[language=Python]
{
    'C': 0.01,
    'solver': 'newton-cg',
    'max_iter': 1000
}
\end{lstlisting}

They give a mean score of 0.904.

This classification method achieves a mean score superior to 0.85.

\end{Solution}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Part 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Part 4}

\begin{Problem}
    We would like to predict the amount of electricity produced by a windfarm, as a function of the information gathered in a number of physical sensors (e.g. speed of the wind, temperature, ...).

    The dataset is stored in \verb|project/ex_4_regression_windfarm/|:
    \begin{itemize}
        \item The inputs x are stored in \verb|inputs.npy|.
        \item The labels y are stored in \verb|labels.npy|.
    \end{itemize}

    The instructions are the same as in 3.

    Your objective should be to obtain a R2 score superior to 0.85 on a test set or as a cross validation score.

    \href{https://fr.wikipedia.org/wiki/Coefficient_de_d%C3%A9termination}{Coefficient of determination}

    \href{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html}{scikit-learn r2 score}

    Several methods might work, including some methods that we have not explicitly studied in the class. Do not hesitate to try such methods.
\end{Problem}

\begin{Solution}

Similarly to the previous part, we tried 4 different regression models, until we arrived to an accuracy superior to 0.85. The models we tried are Linear regression, Polynomial regression, Ridge regression, and Lasso regression. We briefly considered using Logistic regression before realizing that the dependent variable needs to be binary for it to work. For each model we tried tuning the hyperparameters (except for linear regression and polynomial regression) and checked the result with cross validation.

\subsection*{Linear regression}

See \verb|linear_regression.py| for the code.

Mean R2: 0.688

\subsection*{Polynomial regression}

See \verb|polynomial_regression.py| for the code.

Mean R2 (degree=2): 0.750

Mean R2 (degree=3): 0.722

The reduced accuracy with degree=3 can be explained by overfitting.

degree=4 is too complex to be tested on our computers.

This method yields better results than linear regression but is still not enough.

\newpage

\subsection*{Ridge regression}

See \verb|ridge.py| for the code.

Mean R2: 0.765

\subsection*{Lasso regression}

See \verb|lasso.py| for the code.

Mean R2: 0.887

This is a satisfactory solution.

\subsection*{VIF / multicollinearity}

See \verb|data_vif.py| for the code.

The mean VIF of the dataset is: 7.826

Standard deviation of VIF: 0.846

The VIF of the data is moderately high, which is a sign of multicollinearity.

This could explain why Ridge and Lasso regression are better for this dataset.

\end{Solution}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Part 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Part 5}

\begin{Problem}
    Pick a dataset and perform a supervised learning on it. Ideally, your algorithm should answer an interesting question about the dataset. The supervised learning can then be either a classification or a regression.

    You are free to choose the dataset within the following constraints:
    \begin{itemize}
        \item several hundreds of lines
        \item at least 6 attributes (columns), the first being a unique id
        \item some features may be categorical (non quantitative).
    \end{itemize}

    If necessary, you can tweak an existing dataset in order to artificially make it possible to apply analysis ans visualization techniques. Example resources to find datasets:
    \begin{itemize}
        \item \href{https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research}{Link 1}
        \item \href{https://perso.telecom-paristech.fr/eagan/class/igr204/datasets}{Link 2}
        \item \href{https://github.com/awesomedata/awesome-public-datasets}{Link 3}
        \item \href{https://www.kaggle.com/datasets}{Link 4}
    \end{itemize}

    You could start with a general analysis of the dataset, with for instance a file analysis.py that studies:
    \begin{itemize}
        \item histograms of quantitative variables with a comment on important statistical aspects, such as means, standard deviations, etc.
        \item A study of potential outliers
        \item Correlation matrices (maybe not for all variables)
        \item Any interesting analysis : if you have categorical data, with categories are represented most ? To what extent ?
    \end{itemize}

    If the dataset is very large you may also extract a random sample of the dataset to build histogram or compute correlations. You can discuss whether the randomness of the sample has an important influence on the analysis result (this will depend on the dataset).

    Whether it is a classification or a regression, you must provide an evaluation of your processing. For supervised learning, this could be an average squared error, coefficient of determination (R2 score), etc (\url{https://scikit-learn.org/stable/modules/model_evaluation.html}).

    Short docstrings in the python files will be appreciated, at least at the beginning of each file.

    In your report, you could include for instance:
    \begin{itemize}
        \item general informations on the dataset found in the analysis file.
        \item a potential comparison between several algorithm / models that you explored, if relevant
        \item a presentation of the method used to tune the algorithms (choice of hyperparameters, cross validation, etc).
        \item a short discussion of the results
    \end{itemize}

    Feel free to add useful visualizations for each step of your processing.
\end{Problem}

\begin{Solution}

    For this exercise we chose the \href{https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-10-29}{nyc\_squirrels dataset}, it comes from a census where over 300 volunteers counted and observed the squirels living in New York.

    This dataset contains 3023 rows and 36 columns.

    Our objective will be to predict when a squirrel approaches, this measure is interesting because sqirrels are cute and I want them to eat out of my hand.

    \subsection*{Simplifying the dataset}

    Some of the columns are numerical (longitude, latitude, date, etc...).

    Some of the columns are binary (climbing, approaches, tail\_twiches, etc...).

    Some of the columns are strings (fur color, notes by the volunteer, a unique id, etc...).

    There are some values that can be dropped immidiately:
    \begin{itemize}
        \item unique\_squirrel\_id: a unique id that looks like \verb|37F-PM-1014-03|
        \item lat\_long: latitude and longitude of the sigthing, there are already a lat and a long feature in the dataset
        \item hectare: ID tag, which is derived from the hectare grid used to divide and count the park area, it is redundant with lat and long
    \end{itemize}

    A lot of the features are strings, but a lot of the time these features are not set.

    We tried 2 methods:
    \begin{itemize}
        \item if the feature is set 1 else 0 (see \verb|simplify_dataset.py|)
        \item using one hot encoding (see \verb|one_hot_encoding.py|)
    \end{itemize}

    \subsection*{Prediction}

    We then used a Logistic regression model using the approaches feature as the label.

    With both ways of simplyfing the dataset we get the same accuracy: 0.941.

    Adding and removing features doesn't seem to affect the accuracy at all, this probably means there is a problem.
\end{Solution}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
